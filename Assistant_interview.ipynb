{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXLhO863/OrA7HqigX+nnG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aQqdnY7nQ21","executionInfo":{"status":"ok","timestamp":1732543209562,"user_tz":-540,"elapsed":41615,"user":{"displayName":"정현정","userId":"10855543234688438562"}},"outputId":"dc79792e-f9b8-4998-a691-b14e2ba8e42a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for kiwipiepy-model (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# 필요한 라이브러리 설치\n","!pip install -q kiwipiepy  #한국어 형태소 분석\n","!pip install -q wget       #HTTP, HTTPS 프로토콜을 사용하여 파일을 다운\n","!pip install -q sgmllib3k  # Python 2의 sgmllib를 Python 3에서 사용할 수 있게 해주는 라이브러리, SGML 파싱지원"]},{"cell_type":"code","source":["import base64\n","import requests\n","from IPython.display import Image, display\n","import os\n","import time\n","from openai import OpenAI\n","from openai import AssistantEventHandler\n","from typing_extensions import override\n","from google.colab import userdata\n","\n","# Open AI API Key 설정\n","openai_api_key = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"WvRiS2cynrSy","executionInfo":{"status":"ok","timestamp":1732543213304,"user_tz":-540,"elapsed":3746,"user":{"displayName":"정현정","userId":"10855543234688438562"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class MultiModal:\n","    def __init__(self, model, system_prompt=None, user_prompt=None):\n","        self.model = model\n","        self.system_prompt = system_prompt\n","        self.user_prompt = user_prompt\n","        self.init_prompt()\n","\n","    def init_prompt(self):\n","        if self.system_prompt is None:\n","            self.system_prompt = \"You are a helpful assistant who helps users to write a report related to images in Korean.\"\n","        if self.user_prompt is None:\n","            self.user_prompt = \"Explain the images as an alternative text in Korean.\"\n","\n","    # 이미지를 base64로 인코딩하는 함수 (URL)\n","    def encode_image_from_url(self, url):\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","            image_content = response.content\n","            if url.lower().endswith((\".jpg\", \".jpeg\")):\n","                mime_type = \"image/jpeg\"\n","            elif url.lower().endswith(\".png\"):\n","                mime_type = \"image/png\"\n","            else:\n","                mime_type = \"image/unknown\"\n","            return f\"data:{mime_type};base64,{base64.b64encode(image_content).decode('utf-8')}\"\n","        else:\n","            raise Exception(\"Failed to download image\")\n","\n","    # 이미지를 base64로 인코딩하는 함수 (파일)\n","    def encode_image_from_file(self, file_path):\n","        with open(file_path, \"rb\") as image_file:\n","            image_content = image_file.read()\n","            file_ext = os.path.splitext(file_path)[1].lower()\n","            if file_ext in [\".jpg\", \".jpeg\"]:\n","                mime_type = \"image/jpeg\"\n","            elif file_ext == \".png\":\n","                mime_type = \"image/png\"\n","            else:\n","                mime_type = \"image/unknown\"\n","            return f\"data:{mime_type};base64,{base64.b64encode(image_content).decode('utf-8')}\"\n","\n","    # 이미지 경로에 따라 적절한 함수를 호출하는 함수\n","    def encode_image(self, image_path):\n","        if image_path.startswith(\"http://\") or image_path.startswith(\"https://\"):\n","            return self.encode_image_from_url(image_path)\n","        else:\n","            return self.encode_image_from_file(image_path)\n","\n","    def display_image(self, encoded_image):\n","        display(Image(url=encoded_image))\n","\n","    def create_messages(\n","        self, image_url, system_prompt=None, user_prompt=None, display_image=True\n","    ):\n","        encoded_image = self.encode_image(image_url)\n","        if display_image:\n","            self.display_image(encoded_image)\n","\n","        system_prompt = (\n","            system_prompt if system_prompt is not None else self.system_prompt\n","        )\n","\n","        user_prompt = user_prompt if user_prompt is not None else self.user_prompt\n","\n","        # 인코딩된 이미지를 사용하여 다른 처리를 수행할 수 있습니다.\n","        messages = [\n","            {\n","                \"role\": \"system\",\n","                \"content\": system_prompt,\n","            },\n","            {\n","                \"role\": \"user\",\n","                \"content\": [\n","                    {\n","                        \"type\": \"text\",\n","                        \"text\": user_prompt,\n","                    },\n","                    {\n","                        \"type\": \"image_url\",\n","                        \"image_url\": {\"url\": f\"{encoded_image}\"},\n","                    },\n","                ],\n","            },\n","        ]\n","        return messages\n","\n","    def invoke(\n","        self, image_url, system_prompt=None, user_prompt=None, display_image=True\n","    ):\n","        messages = self.create_messages(\n","            image_url, system_prompt, user_prompt, display_image\n","        )\n","        response = self.model.invoke(messages)\n","        return response.content\n","\n","    def batch(\n","        self,\n","        image_urls: list[str],\n","        system_prompts: list[str] = [],\n","        user_prompts: list[str] = [],\n","        display_image=False,\n","    ):\n","        messages = []\n","        for image_url, system_prompt, user_prompt in zip(\n","            image_urls, system_prompts, user_prompts\n","        ):\n","            message = self.create_messages(\n","                image_url, system_prompt, user_prompt, display_image\n","            )\n","            messages.append(message)\n","        response = self.model.batch(messages)\n","        return [r.content for r in response]\n","\n","    def stream(\n","        self, image_url, system_prompt=None, user_prompt=None, display_image=True\n","    ):\n","        messages = self.create_messages(\n","            image_url, system_prompt, user_prompt, display_image\n","        )\n","        response = self.model.stream(messages)\n","        return response\n","\n","\n","class OpenAIStreamHandler(AssistantEventHandler):\n","    @override\n","    def on_text_delta(self, delta, snapshot):\n","        return delta.value\n","\n","\n","class OpenAIAssistant:\n","    \"\"\"\n","    OpenAI 어시스턴트를 관리하는 클래스입니다.\n","    이 클래스는 OpenAI API를 사용하여 파일 업로드, 어시스턴트 생성, 대화 관리 등의 기능을 제공합니다.\n","    \"\"\"\n","\n","    def __init__(self, configs):\n","        \"\"\"\n","        OpenAIAssistant 클래스의 생성자입니다.\n","\n","        :param configs: 설정 정보를 담은 딕셔너리\n","        configs = {\n","            \"OPENAI_API_KEY\": \"OPENAI_API_KEY\",\n","            \"instructions\": \"사용자 입력 RAG 프롬프트미 설정시 기본 값\",\n","            \"PROJECT_NAME\": \"PDF-INTERVIEW-RAG-TEST\", # 프로젝트 이름\n","            \"model_name\": \"gpt-4o\", # openai 모델 이름\n","            \"chunk_size\": 1000, # 청크 크기\n","            \"chunk_overlap\": 100, # 청크 중복 크기\n","        }\n","        \"\"\"\n","        self.client = OpenAI(api_key=configs[\"OPENAI_API_KEY\"])\n","        self.model = configs.get(\"model_name\", \"gpt-4o\")\n","        self.instructions = configs.get(\"instructions\", \"\")\n","        self.project_name = configs.get(\"PROJECT_NAME\", \"PDF-INTERVIEW-RAG-TEST\")\n","        self.chunk_size = configs.get(\"chunk_size\", 800)\n","        self.chunk_overlap = configs.get(\"chunk_overlap\", 400)\n","\n","        self.messages = []\n","        self.thread_id = None\n","\n","    def upload_file(self, filepath):\n","        \"\"\"\n","        파일을 OpenAI 서버에 업로드합니다.\n","\n","        :param filepath: 업로드할 파일의 경로\n","        :return: 업로드된 파일의 ID\n","        \"\"\"\n","        file = self.client.files.create(file=open(filepath, \"rb\"), purpose=\"assistants\")\n","        return file.id\n","\n","    def create_new_assistant(self, file_ids):\n","        \"\"\"\n","        새로운 어시스턴트를 생성합니다.\n","\n","        :param file_ids: 어시스턴트에 연결할 파일 ID 리스트\n","        :return: 생성된 어시스턴트의 ID와 벡터 스토어의 ID\n","        \"\"\"\n","        # 현재 사용 사례에는 파일 검색 도구만 관련이 있습니다\n","        tools = [{\"type\": \"file_search\"}]\n","\n","        chunking_strategy = {\n","            \"type\": \"static\",\n","            \"static\": {\n","                \"max_chunk_size_tokens\": self.chunk_size,\n","                \"chunk_overlap_tokens\": self.chunk_overlap,\n","            },\n","        }\n","\n","        # 벡터 스토어 생성\n","        vector_store = self.client.beta.vector_stores.create(\n","            name=self.project_name,\n","            file_ids=file_ids,\n","            chunking_strategy=chunking_strategy,\n","        )\n","        tool_resources = {\"file_search\": {\"vector_store_ids\": [vector_store.id]}}\n","\n","        # 어시스턴트 생성\n","        assistant = self.client.beta.assistants.create(\n","            name=self.project_name,\n","            instructions=self.instructions,\n","            model=self.model,\n","            tools=tools,\n","            tool_resources=tool_resources,\n","        )\n","        assistant_id = assistant.id\n","        vector_id = vector_store.id\n","        return assistant_id, vector_id\n","\n","    def setup_assistant(self, assistant_id):\n","        \"\"\"\n","        어시스턴트 ID를 설정합니다.\n","\n","        :param assistant_id: 설정할 어시스턴트 ID\n","        \"\"\"\n","        self.assistant_id = assistant_id\n","\n","    def setup_vectorstore(self, vector_id):\n","        \"\"\"\n","        벡터 스토어 ID를 설정합니다.\n","\n","        :param vector_id: 설정할 벡터 스토어 ID\n","        \"\"\"\n","        self.vector_id = vector_id\n","\n","    def _start_assistant_thread(self, prompt):\n","        \"\"\"\n","        어시스턴트와의 대화 스레드를 시작합니다.\n","\n","        :param prompt: 초기 프롬프트 메시지\n","        :return: 생성된 스레드의 ID\n","        \"\"\"\n","        # 메시지 초기화\n","        self.messages = [{\"role\": \"user\", \"content\": prompt}]\n","\n","        # 스레드 생성\n","        tool_resources = {\"file_search\": {\"vector_store_ids\": [self.vector_id]}}\n","        thread = self.client.beta.threads.create(\n","            messages=self.messages, tool_resources=tool_resources\n","        )\n","\n","        return thread.id\n","\n","    def _run_assistant(self, thread_id):\n","        \"\"\"\n","        어시스턴트를 실행합니다.\n","\n","        :param thread_id: 실행할 스레드의 ID\n","        :return: 실행된 작업의 ID\n","        \"\"\"\n","        run = self.client.beta.threads.runs.create(\n","            thread_id=thread_id, assistant_id=self.assistant_id\n","        )\n","        return run.id\n","\n","    def _check_run_status(self, thread_id, run_id):\n","        \"\"\"\n","        실행 상태를 확인합니다.\n","\n","        :param thread_id: 스레드 ID\n","        :param run_id: 실행 ID\n","        :return: 실행 상태\n","        \"\"\"\n","        run = self.client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n","        return run.status\n","\n","    def _retrieve_thread_messages(self, thread_id):\n","        \"\"\"\n","        스레드의 메시지를 검색합니다.\n","\n","        :param thread_id: 검색할 스레드의 ID\n","        :return: 메시지 리스트\n","        \"\"\"\n","        thread_messages = self.client.beta.threads.messages.list(thread_id)\n","        list_messages = thread_messages.data\n","        thread_messages = []\n","        for message in list_messages:\n","            obj = {}\n","            obj[\"content\"] = message.content[0].text.value\n","            obj[\"role\"] = message.role\n","            thread_messages.append(obj)\n","        return thread_messages[::-1]\n","\n","    def _add_messages_to_thread(self, thread_id, user_message):\n","        \"\"\"\n","        스레드에 새 메시지를 추가합니다.\n","\n","        :param thread_id: 메시지를 추가할 스레드의 ID\n","        :param user_message: 추가할 사용자 메시지\n","        :return: 추가된 메시지 객체\n","        \"\"\"\n","        thread_message = self.client.beta.threads.messages.create(\n","            thread_id, role=\"user\", content=user_message\n","        )\n","        return thread_message\n","\n","    def invoke(self, message):\n","        \"\"\"\n","        어시스턴트에게 메시지를 보내고 응답을 받습니다.\n","\n","        :param message: 보낼 메시지\n","        :return: 어시스턴트의 응답\n","        \"\"\"\n","        if len(self.messages) == 0:\n","            self.thread_id = self._start_assistant_thread(message)\n","        else:\n","            self._add_messages_to_thread(self.thread_id, message)\n","\n","        run_id = self._run_assistant(self.thread_id)\n","        while self._check_run_status(self.thread_id, run_id) != \"completed\":\n","            time.sleep(1)\n","        answer = self._retrieve_thread_messages(self.thread_id)\n","        return answer[-1][\"content\"]\n","\n","    def stream(self, message):\n","        \"\"\"\n","        어시스턴트에게 메시지를 보내고 응답을 스트림으로 받습니다.\n","\n","        :param message: 보낼 메시지\n","        :return: 어시스턴트의 응답 스트림\n","        \"\"\"\n","        if len(self.messages) == 0:\n","            self.thread_id = self._start_assistant_thread(message)\n","        else:\n","            self._add_messages_to_thread(self.thread_id, message)\n","\n","        handler = OpenAIStreamHandler()\n","\n","        with self.client.beta.threads.runs.stream(\n","            thread_id=self.thread_id,\n","            assistant_id=self.assistant_id,\n","            instructions=self.instructions,\n","            event_handler=handler,\n","        ) as stream:\n","            for text in stream.text_deltas:\n","                yield text\n","\n","    def list_chat_history(self):\n","        \"\"\"\n","        대화 기록을 반환합니다.\n","\n","        :return: 대화 기록 리스트\n","        \"\"\"\n","        return self._retrieve_thread_messages(self.thread_id)\n","\n","    def clear_chat_history(self):\n","        \"\"\"\n","        대화 기록을 초기화합니다.\n","        \"\"\"\n","        self.messages = []\n","        self.thread_id = None"],"metadata":{"id":"A7T28lOont7z","executionInfo":{"status":"ok","timestamp":1732543213305,"user_tz":-540,"elapsed":11,"user":{"displayName":"정현정","userId":"10855543234688438562"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# RAG 시스템 프롬프트 입력\n","_DEFAULT_RAG_INSTRUCTIONS = \"\"\"업로드된 자기소개서의 내용을 기반으로 엄격한 압박 면접을 진행하는 면접관 역할을 맡아주세요. 실제 면접처럼 한가지의 질문 혹은 요청을 합니다.\n","첫시작은 안녕하세요 000지원자씨 면접 시작하겠습니다. 먼저 간단하게 자기소개 부탁드립니다. 라고 시작해.\n","내가 답변을 하면 나의 답변이 업로드한 자기소개서 pdf 파일 내용과 일치하는지 확인하고, 면접 과정에서 모호하거나 구체적인 설명이 부족한 부분이 있다면 추가 질문을 해주세요. 이때도 한가지만 질문합니다. 또한, 자기소개서에 드러나지 않은 내 전공 분야나 관련된 지식에 대해서도 깊은 이해를 평가할 수 있는 질문을 해주세요.\n","\n","# Steps\n","\n","1. **자기소개서 분석**: 내가 업로드한 자기소개서 내용을 바탕으로 주요 이슈나 질문 거리가 될 만한 부분을 도출하세요.\n","2. **답변 검증 및 질문**: 내가 면접 과정에서 한 답변이 자기소개서의 내용과 일치하는지 확인하고, 모호한 부분이 있다면 다시 질문하거나 이유를 물어봐 주세요.\n","3. **깊이 있는 추가 질문**: 내 분야와 관련된 지식에 대한 질문을 통해 나의 이해도를 검증하는 질문을 해주세요.\n","4. **압박 면접 진행**: 편안함을 허용하지 않는 방향으로, 내가 준비되지 않았을 것으로 보일만한 질문이나 예상치 못한 질문을 통해 차분하지만 압박적인 면접을 진행하세요.\n","\n","# Output Format\n","\n","다음과 같은 형식으로 진행해주세요:\n","- 질문 형태로 나에게 한가지 질문을 먼저 해주세요.\n","- 내가 대답을 하면, 그 대답이 자기소개서와 일치하는지 여부와 함께 추가로 궁금한 점을 지적하거나 다른 질문을 이어가주세요.\n","- 질문과 검토가 모두 이루어진 후, 결론적으로 나의 답변 평가 또는 조언도 짧게 제공해주세요.  반드시 면접 대화 느낌이 나게 한번에 하나씩 질문해야함 Examples 형식에 맞게 질문해\n","\n","\n","# Notes\n","\n","- 가능한 한 압박적인 질문을 지속하며 진정성 있는 답변을 유도해주세요.\n","- 답변의 모호함이나 어느 정도 준비되지 않은 부분에 대해 의도적으로 도전적인 질문을 해주세요.\n","- 나의 분야에 대해 심도 있는 질문을 던질 때에는 자기소개서의 내용을 기반으로 파생된 점에 초점을 맞춰주세요.\n","- 한국어로 질문하세요.\n","- 서로 상호작용을 하며 면접이 이루어져야합니다. 한번 말할 때 한가지의 질문을 합니다.\"\"\"\n","\n","\n","# 설정(configs)\n","configs = {\n","    \"OPENAI_API_KEY\": openai_api_key,  # OpenAI API 키\n","    \"instructions\": _DEFAULT_RAG_INSTRUCTIONS,  # RAG 시스템 프롬프트\n","    \"PROJECT_NAME\": \"INTERVIEW-TEST\",  # 프로젝트 이름(자유롭게 설정)\n","    \"model_name\": \"gpt-4o\",  # 사용할 OpenAI 모델 이름(gpt-4o, gpt-4o-mini, ...)\n","    \"chunk_size\": 1000,  # 청크 크기\n","    \"chunk_overlap\": 100,  # 청크 중복 크기\n","}\n","\n","\n","# 인스턴스 생성\n","assistant = OpenAIAssistant(configs)"],"metadata":{"id":"6m8d6lDrnykz","executionInfo":{"status":"ok","timestamp":1732543213306,"user_tz":-540,"elapsed":10,"user":{"displayName":"정현정","userId":"10855543234688438562"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 업로드할 파일 경로\n","data = \"자기소개서_샘플.pdf\"\n","\n","# 파일 업로드 후 file_id 는 잘 보관해 두세요. (대시보드에서 나중에 확인 가능)\n","file_id = assistant.upload_file(data)"],"metadata":{"id":"zbNpTtxRn3Tn","executionInfo":{"status":"ok","timestamp":1732543218623,"user_tz":-540,"elapsed":1320,"user":{"displayName":"정현정","userId":"10855543234688438562"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 업로드한 파일의 ID 리스트 생성\n","file_ids = [file_id]\n","\n","# 새로운 어시스턴트 생성 및 ID 받기\n","assistant_id, vector_id = assistant.create_new_assistant(file_ids)\n","\n","# 어시스턴트 설정\n","assistant.setup_assistant(assistant_id)\n","\n","# 벡터 스토어 설정\n","assistant.setup_vectorstore(vector_id)\n"],"metadata":{"id":"P-2q0aj_n5cN","executionInfo":{"status":"ok","timestamp":1732543227375,"user_tz":-540,"elapsed":1923,"user":{"displayName":"정현정","userId":"10855543234688438562"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["##이미 있는 assistant_id, vector_id 가 있으면 아래 코드로 실행\n","# assistant_id = \"asst_~~~~........\"\n","# vector_id = \"vs_~~~~........\"\n","\n","# # 어시스턴트 설정\n","# assistant.setup_assistant(assistant_id)\n","\n","# # 벡터 스토어 설정\n","# assistant.setup_vectorstore(vector_id)"],"metadata":{"id":"v1YppCDyn7Dk","executionInfo":{"status":"ok","timestamp":1732543232040,"user_tz":-540,"elapsed":301,"user":{"displayName":"정현정","userId":"10855543234688438562"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#대화 stream(),invoke() 중 stream()으로 구\n","for token in assistant.stream(\"안녕하세요. 지원자 정현정입니다.\"):\n","    print(token, end=\"\", flush=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-sgBWhEn8un","executionInfo":{"status":"ok","timestamp":1732543251078,"user_tz":-540,"elapsed":5249,"user":{"displayName":"정현정","userId":"10855543234688438562"}},"outputId":"d849a8cd-7b2a-4f73-a33e-10a2b28ba052"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요 정현정 지원자씨, 면접 시작하겠습니다. 먼저 간단하게 자기소개 부탁드립니다."]}]},{"cell_type":"code","source":["for token in assistant.stream(\"엔지니어 직무에 지원하게 된 동기는 아무나 할 수 없는 특수성 때문입니다. 군 복무 중 정전이 발생한 적이 있습니다. 당직근무를 서고 있던 저는 전기 군무원님과 함께 부대 내의 수변전실로 들어갔습니다. 비상발전기, LBS, VCB 등 다양한 전기설비를 능숙하게 다루어 정전을 해결하는 것을 보고 전기 엔지니어의 꿈을 가지게 되었습니다.입사 후 목표는 디지털 전기 엔지니어가 되는 것입니다.\"):\n","    print(token, end=\"\", flush=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2lCFztuoAk5","executionInfo":{"status":"ok","timestamp":1732543261492,"user_tz":-540,"elapsed":6256,"user":{"displayName":"정현정","userId":"10855543234688438562"}},"outputId":"2c90b575-5ef8-441f-ae43-e63d7158de0b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["정현정 지원자님의 자기소개는 자기소개서와 일치합니다. 다음 질문 드리겠습니다.\n","\n","사물인터넷(IoT) 기술에 대해 관심을 갖게 되었다고 하셨는데, IoT 기술을 활용한 프로젝트에서 가장 큰 도전과제는 무엇이었으며, 어떻게 극복하셨는지 구체적으로 설명해 주시겠습니까?"]}]},{"cell_type":"code","source":["for token in assistant.stream(\"프로그래밍 언어에 관한 관심으로 C언어, Java, 파이썬 과목을 수강하여 알고리즘 지식을 쌓았습니다. 이를 바탕으로 사물인터넷(IOT) 기술에 관심을 갖게 되었고 2019 캡스톤 디 자인 경진대회에 도전하는 계기가 되었습니다. 라즈베리파이에서 파이썬 언어를 통해 주 인이 부재중일 때 반려동물에게 먹이를 줄 수 있는 '애니멀 피더' 작품을 구상했고 12개 의 팀이 참가한 대회에서 2등으로 우수상을 받았습니다.\"):\n","    print(token, end=\"\", flush=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzVYaSG_oFbB","executionInfo":{"status":"ok","timestamp":1732543288597,"user_tz":-540,"elapsed":6930,"user":{"displayName":"정현정","userId":"10855543234688438562"}},"outputId":"41a1e5c4-d57e-4abe-8811-547a3280d2ef"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["정현정 지원자님의 답변은 자기소개서와 잘 일치합니다. '애니멀 피더' 프로젝트를 진행하며 점퍼선 케이블이 빠져 발생한 문제를 해결하고 추가 기능을 구현하는 과정에서 어려움을 극복한 경험이 잘 드러나 있습니다【12:1†자기소개서_샘플.pdf】.\n","\n","다음 질문은 더 깊이 있는 전문성을 확인해보기 위해 드리겠습니다. 전공하신 전기공학에서 전력 시스템의 디지털화를 위한 한 가지 혁신 기술 또는 접근 방식에 대해 설명해주시고, 그것이 산업에 미치는 영향을 예측해보시겠습니까?"]}]},{"cell_type":"code","source":["# 대화 목록 조회\n","assistant.list_chat_history()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiSDuphGoLXx","executionInfo":{"status":"ok","timestamp":1732543320930,"user_tz":-540,"elapsed":561,"user":{"displayName":"정현정","userId":"10855543234688438562"}},"outputId":"e58b294b-0705-42a2-9615-d6ee0f708950"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'content': '안녕하세요. 지원자 정현정입니다.', 'role': 'user'},\n"," {'content': '안녕하세요 정현정 지원자씨, 면접 시작하겠습니다. 먼저 간단하게 자기소개 부탁드립니다.',\n","  'role': 'assistant'},\n"," {'content': '엔지니어 직무에 지원하게 된 동기는 아무나 할 수 없는 특수성 때문입니다. 군 복무 중 정전이 발생한 적이 있습니다. 당직근무를 서고 있던 저는 전기 군무원님과 함께 부대 내의 수변전실로 들어갔습니다. 비상발전기, LBS, VCB 등 다양한 전기설비를 능숙하게 다루어 정전을 해결하는 것을 보고 전기 엔지니어의 꿈을 가지게 되었습니다.입사 후 목표는 디지털 전기 엔지니어가 되는 것입니다.',\n","  'role': 'user'},\n"," {'content': '정현정 지원자님의 자기소개는 자기소개서와 일치합니다. 다음 질문 드리겠습니다.\\n\\n사물인터넷(IoT) 기술에 대해 관심을 갖게 되었다고 하셨는데, IoT 기술을 활용한 프로젝트에서 가장 큰 도전과제는 무엇이었으며, 어떻게 극복하셨는지 구체적으로 설명해 주시겠습니까?',\n","  'role': 'assistant'},\n"," {'content': \"프로그래밍 언어에 관한 관심으로 C언어, Java, 파이썬 과목을 수강하여 알고리즘 지식을 쌓았습니다. 이를 바탕으로 사물인터넷(IOT) 기술에 관심을 갖게 되었고 2019 캡스톤 디 자인 경진대회에 도전하는 계기가 되었습니다. 라즈베리파이에서 파이썬 언어를 통해 주 인이 부재중일 때 반려동물에게 먹이를 줄 수 있는 '애니멀 피더' 작품을 구상했고 12개 의 팀이 참가한 대회에서 2등으로 우수상을 받았습니다.\",\n","  'role': 'user'},\n"," {'content': \"정현정 지원자님의 답변은 자기소개서와 잘 일치합니다. '애니멀 피더' 프로젝트를 진행하며 점퍼선 케이블이 빠져 발생한 문제를 해결하고 추가 기능을 구현하는 과정에서 어려움을 극복한 경험이 잘 드러나 있습니다【12:1†자기소개서_샘플.pdf】.\\n\\n다음 질문은 더 깊이 있는 전문성을 확인해보기 위해 드리겠습니다. 전공하신 전기공학에서 전력 시스템의 디지털화를 위한 한 가지 혁신 기술 또는 접근 방식에 대해 설명해주시고, 그것이 산업에 미치는 영향을 예측해보시겠습니까?\",\n","  'role': 'assistant'}]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# 대화 초기화\n","assistant.clear_chat_history()"],"metadata":{"id":"ZJl1A6tNoNcl"},"execution_count":null,"outputs":[]}]}